/* Copyright 2001, 2019 IBM Corporation
 *
 * Redistribution and use in source and binary forms, with or without modification, are permitted provided that the 
 * following conditions are met:
 *
 * 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the 
 * following disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the 
 * following disclaimer in the documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, 
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, 
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR 
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, 
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE 
 * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
 class vc
{
   public:
   double a ;
   double b ;
   double c ;
   double d ;
   double e ;
} ;

static inline double vcm(double x, const vc& avc)
{
   return avc.a * x ;
}

/*
 * This function shows 'tail wagging dog', vc0 and vc1 being materialised in
 * store by a 'bct' loop and move through integer registers
 * The compiler should realise this is equivalent to 'vmcx2', and generate
 * the same code
 */
void vcmx(const vc& vcz, double x0, double& r0, double x1, double& r1)
{
   vc vc0(vcz) ;
   vc vc1(vcz) ;
   double ar0 = vcm(x0,vc0)  ;
   double ar1 = vcm(x1,vc1)  ;
   r0 = ar0 ;
   r1 = ar1 ;
}

double vcme(double x ,const vc& vc) ;

/*
 * When you have to materialise the structure in store, and it is too large
 * to do inline (like vcmx2e), it would be better done with a 'bct' loop or
 * with a call to a library routine which knew it was copying aligned doubles.
 */
void vcmxe(const vc& vcz, double x0, double& r0, double x1, double& r1)
{
   vc vc0(vcz) ;
   vc vc1(vcz) ;
   double ar0 = vcme(x0,vc0)  ;
   double ar1 = vcme(x1,vc1)  ;
   r0 = ar0 ;
   r1 = ar1 ;
}


class vc2
{
   public:
   double a ;
   double b ;
   double c ;
   double d ;
} ;

static inline double vcm2(double x, const vc2& avc)
{
   return avc.a * x ;
}


/*
 * This function is well optimised
 */
void vcmx2(const vc2& vcz, double x0, double& r0, double x1, double& r1)
{
   vc2 vc0(vcz) ;
   vc2 vc1(vcz) ;
   double ar0 = vcm2(x0,vc0)  ;
   double ar1 = vcm2(x1,vc1)  ;
   r0 = ar0 ;
   r1 = ar1 ;
}

double vcm2e(double x ,const vc2& vc) ;

/*
 * This function shows the right way to materialise a 'vc2' in store when
 * you have to, i.e. move it through FP registers.
 * However, the optimiser is missing a trick; it loads values into registers
 * which it should know are already there.
 */
void vcmx2e(const vc2& vcz, double x0, double& r0, double x1, double& r1)
{
   vc2 vc0(vcz) ;
   vc2 vc1(vcz) ;
   double ar0 = vcm2e(x0,vc0)  ;
   double ar1 = vcm2e(x1,vc1)  ;
   r0 = ar0 ;
   r1 = ar1 ;
}

